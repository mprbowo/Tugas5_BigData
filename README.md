# Tugas5_BigData

1. mylist dan myschema berfungsi untuk mendefinisikan variabel mylist dan myschema
2. spark.createDataFrame berfungsi untuk membuat DataFrame baru 
3. parallelize dan toDF berfungsi untuk membuat RDD dari data yang sudah di-parallelisasi dan mengubahnya menjadi DataFrame dengan menggunakan toDF 
4. hadoop, fs, dan put berfungsi untuk mengirim file ke sistem file hadoop 
5. pyspark.sql, SQLContext, createOrReplaceTempView, dan show berfungsi untuk membuat objek SQLContext dan membuat temporary view menggunakan createOrReplaceTempView, kemudian menampilkan data menggunakan show 
6. textFile, map, lambda, strip, StructField, dan StringType berfungsi untuk membaca file teks menggunakan textFile, melakukan pemetaan menggunakan map, melakukan operasi lambda, menghilangkan karakter whitespace dengan strip, mendefinisikan StructField, dan mengubah data menjadi StringType 
7. spark.read.format, jdbc, options, dan load berfungsi untuk membaca data dari JDBC data source menggunakan spark.read.format, kemudian menentukan opsi dan memuat data menggunakan load 
8. show berfungsi untuk menampilkan data 
9. collect, rdd, dan take berfungsi untuk mengumpulkan data menggunakan collect, mengambil sejumlah data dari RDD menggunakan take 
10. makeRDD, Seq, dan createDataset berfungsi untuk membuat RDD baru menggunakan makeRDD dan membuat Dataset baru menggunakan createDataset 
11. filter berfungsi untuk melakukan filter pada DataFrame 
12. as, toDF, dan first berfungsi untuk mengubah kolom menjadi DataFrame, mengubah DataFrame menjadi tabel menggunakan as dan toDF, dan mengambil nilai pertama menggunakan first 
13. listDatabases, listTables, listFunctions, isCached, dan select berfungsi untuk menampilkan daftar database, tabel, dan fungsi, mengecek apakah data di-cache menggunakan isCached, dan memilih kolom menggunakan select 
14, Read dan text berfungsi untuk membaca file teks menggunakan read.text 
15. load, json, format, dan printSchema berfungsi untuk membaca file json menggunakan load, kemudian mencetak skema data menggunakan printSchema 
16. write dan save berfungsi untuk menulis data ke file sistem menggunakan write, kemudian menyimpan data menggunakan save 
17. parquet berfungsi untuk menulis data ke format parquet 
18. Options, inferSchema, csv, header, dan codec berfungsi untuk menentukan opsi untuk pembacaan file csv dan menentukan header dan codec 
